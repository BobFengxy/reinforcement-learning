#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Wed Mar  6 14:12:57 2019

@author: fengxingyu
"""
import numpy as np
import matplotlib.pyplot as plt
import random
import tensorflow as tf

from FD import FDnet
from AT_LSTM import lstm

tf.reset_default_graph()
f=20
m=5
i_episode_sum=300#强化学习次数300次
j_episode_sum=5#每回合5次

RL=FDnet(n_actions=3,fc_dim=256,f=f,m=m,learning_rate=0.02,reward_decay=0.99)


for i_episode in range(i_episode_sum):
    act_mask=random.sample(range(0,f),m)#生成随机不重复的索引
    act_mask.sort()
    mask_1=np.zeros([f],dtype=np.int)
    mask_1[act_mask]=1#生成随机01索引

    observation=mask_1#1*f
    test_data=np.random.uniform(0,10,(f,3))
    # test_data=np.random.randint(50, size=(f,3))
    #print('WWW1')
    #print(act_mask)
    #print(observation)
    for j_episode in range(j_episode_sum):
        action=RL.choose_action(observation,test_data)#1*m 0,1,2
        #print('WWW2')
        print(observation.shape)
        #print('WWW3')

        #print(action)
        ls=lstm()
        act_mask_t=ls.change_mask(act_mask,action,m,f)#1*m 0-19
        #print('WWW4')

        #print(act_mask_t)
        mask_1=np.zeros([f],dtype=np.int)#1*f
        mask_1[act_mask_t]=1
        #print('+'*20)
        #print(mask_1)
        observation_t=mask_1#产生新的mask 1*f 丢入LSTM
        
        reward=ls.at_lstm(observation_t)#丢入lstm得出奖励
        RL.store_transition(observation, action, reward)#存储这一回合的transition
        
    #此回合结束
    
        if j_episode==j_episode_sum-1:
           
            ep_rs_sum = sum(RL.ep_rs)
            
            if 'running_reward' not in globals():
                running_reward=ep_rs_sum
            else:
                running_reward=running_reward*0.99+ep_rs_sum*0.01
                
            vt=RL.learn(test_data)
            break
        observation = observation_t
